{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2169d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse, datetime, json\n",
    "import data_cleaning as clean\n",
    "import fitting as fit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import stat_metrics as stat\n",
    "import utils\n",
    "\n",
    "DATA_FILENAME = 'FLE7_2020.csv'\n",
    "N_ITERS       = 1500\n",
    "\n",
    "# Load behavioral data from CSV\n",
    "data = pd.read_csv(DATA_FILENAME, delimiter=';', header=None).values\n",
    "num_subjects = data.shape[0]\n",
    "\n",
    "# Define the x-axis (0:pi/4:2*pi)\n",
    "xax = utils.X_RANGE\n",
    "\n",
    "# Sort properly the condition, according to the X_RANGE\n",
    "data = clean.sort_condition(data)\n",
    "\n",
    "# Flatten the data to 9x32 for fitting\n",
    "data = data.reshape(num_subjects, -1)  # 9x32 matrix\n",
    "data_tmp = np.zeros((data.shape[0]+1, data.shape[1]))\n",
    "data_tmp[:num_subjects, :] = data   \n",
    "# At the bottom of the original data matrix, added the mean across the subjects\n",
    "data_tmp[-1, :] = np.nanmean(data, axis = 0) \n",
    "data = data_tmp \n",
    "\n",
    "# Prepare X_data (same values for all subjects, repeated)\n",
    "xax = np.tile(xax, 4)\n",
    "x_data = np.ones((data.shape[0], len(xax)))*xax\n",
    "\n",
    "# Fit the data, either sub by sub and all together\n",
    "betas, fit_quality, prediction_subs              = fit.fit_data_sub_B_sub(data, x_data)\n",
    "beta_global, fit_quality_global, prediction_glob = fit.fit_all_together(data[:-1, :], x_data[:-1, :])  \n",
    " \n",
    "utils.fit_result_outcome(betas, fit_quality, beta_global, fit_quality_global, filename = 'model_fitting_results.csv')\n",
    "\n",
    "# Break fitting sub by sub\n",
    "mses_err_sub, rsqr_err_sub = stat.break_fit(data, prediction_subs, N_ITERS)\n",
    "# Break fitting global\n",
    "mses_err_glob, rsqr_err_glob = stat.break_fit(data[:-1, :].ravel(), prediction_glob.ravel(), N_ITERS*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b17f4",
   "metadata": {},
   "source": [
    "### Obtain CI half-width 95% and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preds_, y_preds_, deltas_ = fit.get_confidence_interval(data, x_data, \n",
    "                                                          betas, beta_global, \n",
    "                                                          prediction_subs, \n",
    "                                                          alpha = .05, eps = 1e-5)\n",
    "\n",
    "sub_names = utils.SUB_NAMES + ['AllTogether']\n",
    "utils.prediction_outcome(x_preds_, y_preds_, deltas_, sub_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f29529",
   "metadata": {},
   "source": [
    "### Visualize fittings functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd54fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import visualization_fit as visualize\n",
    "\n",
    "visualize.visualize_fit_n_raw_sub(data, x_data, betas, utils.SUB_NAMES, 'fit_allSubs')\n",
    "visualize.visualize_fit_n_raw_allTogether(data[:-1, :], x_data[:-1, :], beta_global, filename = 'fit_allTogether')\n",
    "\n",
    "print(f'Betas for average across subjects {betas[-1]}')\n",
    "print(f'Betas for all together fit {beta_global}')\n",
    "\n",
    "visualize.visualize_betas(betas, filename = 'betas_subs', betas_to_plot = ['Fovea', 'HM', 'VM', 'Eccentricity'])\n",
    "\n",
    "\n",
    "visualize.visualize_hists(mses_err_sub, \n",
    "                          rsqr_err_sub, \n",
    "                          fit_quality, \n",
    "                          filename = 'random_permutation_distributions_subbysub')\n",
    "\n",
    "visualize.visualize_hists(np.array([mses_err_glob]), \n",
    "                          np.array([rsqr_err_glob]), \n",
    "                          fit_quality_global, \n",
    "                          sub_names = ['All Together'],                          \n",
    "                          filename = 'random_permutation_distributions_allTogether')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_allTog, p_ttest_allTog, ps_single_sub, ps_single_sub_t = stat.get_pvalues([mses_err_glob, rsqr_err_glob], \n",
    "                                                                            [mses_err_sub, rsqr_err_sub],\n",
    "                                                                            fit_quality_global, fit_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022535a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.stat_outcome(ps_single_sub, ps_single_sub_t, \n",
    "                   p_allTog, \n",
    "                   p_ttest_allTog, \n",
    "                   fit_quality_global, fit_quality, filename = 'breakfit_random_perm_quality_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f144ab",
   "metadata": {},
   "source": [
    "## Fit of randomly permuted data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25402596",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "betas_sub_shuffled       = np.zeros((utils.N_ITERS, data.shape[0], len(utils.BETA_INIT)))\n",
    "fit_quality_sub_shuffled = list()\n",
    "start_time   = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "betas_allTogether_shuffled       = np.zeros((utils.N_ITERS, len(utils.BETA_INIT)))\n",
    "fit_quality_allTogether_shuffled = list()\n",
    "start_time   = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "for i in range(utils.N_ITERS):\n",
    "    shuffled_data = np.array([np.random.permutation(row) for row in data])    \n",
    "    betas_sub_shuffled[i, :, :], a, _ = fit.fit_data_sub_B_sub(shuffled_data, x_data, flag_print = False)\n",
    "    fit_quality_sub_shuffled.append(a)\n",
    "    \n",
    "    shuffled_data = np.array([np.random.permutation(row) for row in data])    \n",
    "    betas_allTogether_shuffled[i, :], a, _ = fit.fit_all_together(shuffled_data[:-1, :], x_data[:-1, :], flag_print = False)\n",
    "    fit_quality_allTogether_shuffled.append(a)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        tmp_rmse = fit_quality_allTogether_shuffled[-1][0][0]\n",
    "        tmp_rsqr = fit_quality_allTogether_shuffled[-1][0][1]\n",
    "        print(f\"--------------------------------------------------------------------------------\")\n",
    "        print(f\"Iteration {i + 1}\")\n",
    "        print(f\"RMSE: {tmp_rmse:.4f}, \\\n",
    "              R²: {tmp_rsqr:.4f}\")        \n",
    "            \n",
    "    \n",
    "        tmp_rmse = fit_quality_sub_shuffled[-1][0][0]\n",
    "        tmp_rsqr = fit_quality_sub_shuffled[-1][0][1]\n",
    "\n",
    "        print(f\"RMSE sub: {tmp_rmse:.4f}, \\\n",
    "              R² sub: {tmp_rsqr:.4f}\")        \n",
    "        \n",
    "fit_quality_sub_shuffled = np.array([[j[0], j[1]] for i in fit_quality_sub_shuffled for j in i])        \n",
    "fit_quality_sub_shuffled = fit_quality_sub_shuffled.reshape(1500, 10, 2).transpose(1, 0, 2)\n",
    "\n",
    "fit_quality_allTogether_shuffled = np.array([[i[0][0], i[0][1]]for i in fit_quality_allTogether_shuffled])\n",
    "\n",
    "print(f'Fitting on randomly permuted data: {str(datetime.datetime.now().replace(microsecond=0)-start_time)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ab738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.visualize_hists(np.squeeze(fit_quality_sub_shuffled[:, :, 0]), \n",
    "                          np.squeeze(fit_quality_sub_shuffled[:, :, 1]), \n",
    "                          fit_quality, \n",
    "                          filename = 'random_permutation_fits_subbysub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81870d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.visualize_hists(fit_quality_allTogether_shuffled[:, 0].reshape(1, -1), \n",
    "                          fit_quality_allTogether_shuffled[:, 1].reshape(1, -1), \n",
    "                          fit_quality_global, \n",
    "                          sub_names = ['All Together'],                          \n",
    "                          filename = 'random_permutation_fits_allTogether')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_allTog, p_ttest_allTog, ps_single_sub, ps_single_sub_t = stat.get_pvalues([np.squeeze(fit_quality_allTogether_shuffled[:, 0]), np.squeeze(fit_quality_allTogether_shuffled[:, 1])], \n",
    "                                                                            [np.squeeze(fit_quality_sub_shuffled[:, :, 0]), np.squeeze(fit_quality_sub_shuffled[:, :, 1])],\n",
    "                                                                            fit_quality_global, fit_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.stat_outcome(ps_single_sub, ps_single_sub_t, \n",
    "                   p_allTog, p_ttest_allTog, \n",
    "                   fit_quality_global, fit_quality, filename = 'fit_random_perm_quality_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd086809",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_signif_subs = {n: utils.SUB_NAMES[n] for n, (i, j) in enumerate(ps_single_sub) if ((i>0.05) and (j>0.05)) }\n",
    "not_signif_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ceffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_signif = np.array([i for n, i in enumerate(data) if n not in list(not_signif_subs.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data, either sub by sub and all together\n",
    "betas_signif, fit_quality_signif, prediction_subs_signif              = fit.fit_data_sub_B_sub(data_signif, x_data[:len(data_signif), :])\n",
    "beta_global_signif, fit_quality_global_signif, prediction_glob_signif = fit.fit_all_together(data_signif[:-1, :], x_data[:(len(data_signif)-1), :])  \n",
    "\n",
    "visualize.visualize_fit_n_raw_allTogether(data_signif[:-1, :], \n",
    "                                          x_data[:(len(data_signif)-1), :], \n",
    "                                          beta_global_signif, \n",
    "                                          filename = 'fit_allTogether_only_Signif')\n",
    "\n",
    "print(f'Betas for average across subjects {betas_signif[-1]}')\n",
    "print(f'Betas for all together fit {beta_global_signif}')\n",
    "\n",
    "visualize.visualize_betas(betas, filename = 'betas_subs_only_Signif', \n",
    "                          betas_to_plot = ['Fovea', 'HM', 'VM', 'Eccentricity'], \n",
    "                          not_significant_subs = [utils.SUB_ENUMERATION[i] for i in list(not_signif_subs.keys())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aaff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_global - beta_global_signif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ef155",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_quality_global_signif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_row = [fit_quality_global_signif[0][0], \n",
    "           fit_quality_global_signif[0][1], \n",
    "           beta_global_signif[0], \n",
    "           beta_global_signif[1], \n",
    "           beta_global_signif[2],\n",
    "           beta_global_signif[3], \n",
    "           beta_global_signif[4]]\n",
    "utils.append_row_to_csv(tmp_row, new_index='Only Significant', filename='model_fitting_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
